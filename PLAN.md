# Production-Grade ETL Pipeline Project Plan

## ğŸ“‹ Overview

Build a fully containerized ETL pipeline with:
- Source & Target PostgreSQL databases
- Python ETL service
- dbt transformations
- Airflow orchestration
- GitHub Actions CI/CD

---

## ğŸ—‚ Phase 1: Project Scaffolding

**Goal:** Create the full directory structure

```
docker-actions/
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ dags/
â”‚   â”‚   â””â”€â”€ etl_pipeline_dag.py
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ etl/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ extract.py
â”‚   â”‚   â”œâ”€â”€ load.py
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â””â”€â”€ config.py
â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ test_extract.py
â”‚   â”‚   â””â”€â”€ test_load.py
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ dbt/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ staging/
â”‚   â”‚   â”‚   â”œâ”€â”€ stg_customers.sql
â”‚   â”‚   â”‚   â”œâ”€â”€ stg_orders.sql
â”‚   â”‚   â”‚   â””â”€â”€ schema.yml
â”‚   â”‚   â”œâ”€â”€ intermediate/
â”‚   â”‚   â”‚   â”œâ”€â”€ int_orders_enriched.sql
â”‚   â”‚   â”‚   â””â”€â”€ schema.yml
â”‚   â”‚   â””â”€â”€ marts/
â”‚   â”‚       â”œâ”€â”€ fct_sales.sql
â”‚   â”‚       â”œâ”€â”€ dim_customers.sql
â”‚   â”‚       â””â”€â”€ schema.yml
â”‚   â”œâ”€â”€ dbt_project.yml
â”‚   â”œâ”€â”€ profiles.yml
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ db/
â”‚   â””â”€â”€ init/
â”‚       â””â”€â”€ init_source.sql
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env.example
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci.yml
â”œâ”€â”€ Makefile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .pre-commit-config.yaml
â””â”€â”€ README.md
```

**Tasks:**
- [ ] Create all directories
- [ ] Create placeholder files
- [ ] Set up .gitignore

---

## ğŸ³ Phase 2: Docker Infrastructure

**Goal:** Set up all containers with proper networking

### Containers:
1. **source_db** - PostgreSQL (OLTP source)
2. **target_db** - PostgreSQL (Data Warehouse)
3. **etl** - Python ETL service
4. **dbt** - dbt container
5. **airflow** - Airflow scheduler + webserver

### Requirements:
- [ ] Create docker-compose.yml with all services
- [ ] Configure Docker network (`etl_network`)
- [ ] Set up named volumes for DB persistence
- [ ] Add healthchecks for databases
- [ ] Create .env file for credentials
- [ ] Use multi-stage builds for Python images

---

## ğŸ”„ Phase 3: ETL Service Development

**Goal:** Build modular, production-ready ETL scripts

### Files:
- `config.py` - Environment variables, DB connections
- `extract.py` - Extract data from source DB
- `load.py` - Load data to target DB (raw schema)
- `main.py` - Orchestrate ETL process

### Features:
- [ ] Structured logging
- [ ] Type hints throughout
- [ ] Idempotent operations (upserts)
- [ ] Incremental loading via watermark column
- [ ] Error handling with retries
- [ ] Unit tests with pytest

### Sample Tables:
- `customers` (id, name, email, created_at, updated_at)
- `orders` (id, customer_id, amount, status, created_at, updated_at)
- `products` (id, name, price, category, created_at, updated_at)

---

## ğŸ“Š Phase 4: dbt Layer

**Goal:** Transform raw data into analytics-ready models

### Layers:
1. **Staging** (`stg_`)
   - Clean and rename columns
   - Cast data types
   - 1:1 mapping from source

2. **Intermediate** (`int_`)
   - Business logic joins
   - Calculations
   - Enrichments

3. **Marts** (`fct_`, `dim_`)
   - Final analytics tables
   - Star schema design

### Requirements:
- [ ] Create dbt_project.yml
- [ ] Create profiles.yml (for target DB connection)
- [ ] Build staging models with schema.yml tests
- [ ] Build intermediate models
- [ ] Build mart models (at least one incremental)
- [ ] Add tests: unique, not_null, relationships
- [ ] Configure documentation generation

---

## ğŸŒ¬ Phase 5: Airflow Orchestration

**Goal:** Automate pipeline execution

### DAG Structure:
```
extract_load_task â†’ dbt_run_task â†’ dbt_test_task
```

### Requirements:
- [ ] Create Airflow Dockerfile
- [ ] Configure DockerOperator for each task
- [ ] Set up proper dependency chaining
- [ ] Add retries (3 attempts, 5 min delay)
- [ ] Use environment variables (no hardcoded creds)
- [ ] Configure daily schedule
- [ ] Add proper logging

---

## ğŸ” Phase 6: CI/CD Pipeline

**Goal:** Automate testing and deployment with GitHub Actions

### Workflow Steps:
1. **Lint**
   - [ ] black (Python formatting)
   - [ ] flake8 (Python linting)
   - [ ] sqlfluff (SQL linting)

2. **Test**
   - [ ] Run pytest for ETL

3. **Build**
   - [ ] Build Docker images
   - [ ] Use caching for faster builds

4. **Integration**
   - [ ] Spin up docker-compose
   - [ ] Wait for healthchecks
   - [ ] Run ETL
   - [ ] Run dbt run
   - [ ] Run dbt test

5. **Cleanup**
   - [ ] Tear down containers
   - [ ] Fail pipeline on any error

---

## ğŸ“ Phase 7: Documentation & Quality

**Goal:** Professional-grade documentation and tooling

### Tasks:
- [ ] Write comprehensive README.md
- [ ] Add architecture diagram
- [ ] Create Makefile with commands:
  - `make build` - Build all images
  - `make up` - Start services
  - `make down` - Stop services
  - `make etl` - Run ETL manually
  - `make dbt-run` - Run dbt
  - `make test` - Run all tests
  - `make lint` - Run linters
- [ ] Set up pre-commit hooks
- [ ] Create .env.example with sample values

---

## âœ… Checklist Summary

| Phase | Component | Status |
|-------|-----------|--------|
| 1 | Project Structure | âœ… |
| 2 | Docker Infrastructure | âœ… |
| 3 | ETL Service | âœ… |
| 4 | dbt Layer | â¬œ |
| 5 | Airflow DAG | â¬œ |
| 6 | CI/CD Pipeline | â¬œ |
| 7 | Documentation | â¬œ |

---

## ğŸš€ Execution Order

1. **Phase 1** â†’ Scaffold structure
2. **Phase 2** â†’ Docker setup (databases first)
3. **Phase 3** â†’ ETL development + testing
4. **Phase 4** â†’ dbt models + tests
5. **Phase 5** â†’ Airflow DAG
6. **Phase 6** â†’ GitHub Actions CI
7. **Phase 7** â†’ Polish docs and tooling

---

## ğŸ“Œ Notes

- Each phase should be committed separately with meaningful messages
- Test locally before pushing to CI
- Use feature branches for each phase
- Document any deviations from the plan
